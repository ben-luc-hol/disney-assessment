{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-04T06:40:12.475948Z",
     "start_time": "2024-12-04T06:40:10.293078Z"
    }
   },
   "source": [
    "from src import ProjectManager\n",
    "from src import MovieScraper\n",
    "from src import DatabaseOps\n",
    "from src import MoviePreprocessor\n",
    "from src import MovieEmbedder\n",
    "from src import SearchAndRetrieval\n",
    "import pandas as pd"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# DISNEY+ LLM DATA ENGINEER PRE-ASSIGNMENT",
   "id": "62dbe06f025d650c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Note: Typically, in deployment this would probably be wrapped in an execution/orchestration class. \n",
    "\n",
    "See `disney_etl.py` in the source code for an example of how this might be done.\n",
    "\n",
    "For the purposes of this demo, I'm instantiating and using each of the worker classes individually for clarity."
   ],
   "id": "1f934a38eac84fc0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-04T06:40:14.209043Z",
     "start_time": "2024-12-04T06:40:14.205922Z"
    }
   },
   "cell_type": "code",
   "source": "pm = ProjectManager()",
   "id": "d09e682713931ff6",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1. Data Ingestion",
   "id": "9b0ae0839de0c678"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-04T05:44:52.864475Z",
     "start_time": "2024-12-04T05:44:52.860469Z"
    }
   },
   "cell_type": "code",
   "source": "scraper = MovieScraper(project_manager=pm)",
   "id": "f46795553bb769e6",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "### a. The dataset\n",
    "\n",
    "The dataset used fetches all of Disney's listed movie titles (699 in total) along with metadata and stores each as a JSON object.\n",
    "\n",
    "See *data_ingestion.py* in the source code.\n"
   ],
   "id": "12275fbb5ee143e4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-04T05:55:16.062309Z",
     "start_time": "2024-12-04T05:44:55.777946Z"
    }
   },
   "cell_type": "code",
   "source": "scraper.run()",
   "id": "3cb47f981799af1a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Iterating through Disney's API by page:   0%|          | 0/18 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "258aae5d48bc4e1eb1e33cf2cf01f177"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Processing movies:   0%|          | 0/699 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4b45c1d11cc340f0be89c57fc0ad2db0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### b. Database operations",
   "id": "e05165a8dc40e611"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Here, I load the raw JSON records into a SQLite database (`movie_data.db`).\n",
    "Using a SQLite database is convenient since there aren't that many records, but it does the job for querying purposes and mimics the code structure one might use in production. \n",
    "\n",
    "See `database_utils.py` for source code."
   ],
   "id": "12cf26951b7f583c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-04T06:40:17.649836Z",
     "start_time": "2024-12-04T06:40:17.644913Z"
    }
   },
   "cell_type": "code",
   "source": "db = DatabaseOps(pm)",
   "id": "32ab22de10e619dd",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-04T06:10:01.218548Z",
     "start_time": "2024-12-04T06:10:01.213670Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#directory to get JSON files from\n",
    "raw_dir = pm.directories.get(\"raw\") / \"movie-data\""
   ],
   "id": "ad1a2a42ecb3fcb0",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-04T06:10:19.257547Z",
     "start_time": "2024-12-04T06:10:18.469704Z"
    }
   },
   "cell_type": "code",
   "source": "db.batch_insert_from_json_files(raw_dir)",
   "id": "22a233f372ab5ef5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loading movies to database: 0it [00:00, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0e9f78a1ac8b4e278eb8589b28cb9062"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(699, 0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2. Data Preprocessing",
   "id": "eb47c7fa4fa3dd5b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-04T06:40:19.988823Z",
     "start_time": "2024-12-04T06:40:19.985336Z"
    }
   },
   "cell_type": "code",
   "source": "preprocessor = MoviePreprocessor(project_manager=pm)",
   "id": "4a10531c4bbe5321",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-04T06:40:20.410402Z",
     "start_time": "2024-12-04T06:40:20.176464Z"
    }
   },
   "cell_type": "code",
   "source": "movies = db.get_all_movies()",
   "id": "467ea499ba9c26c3",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-04T06:40:20.443450Z",
     "start_time": "2024-12-04T06:40:20.411200Z"
    }
   },
   "cell_type": "code",
   "source": "preprocessed_movies = preprocessor.preprocess_movies(movies)",
   "id": "e9adc5723778a200",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Preprocessing movies:   0%|          | 0/699 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5d35f350a9324b9db61b862e6bfed4f4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "### a. Transformation(s) & b. storage / retrieval optimization\n",
    "The dataset is already fairly organized due to the way it was collected, but there's an additional data preprocessing step that processes text data prior to loading it into the SQLite database.\n",
    "See `data_preprocessing` in the source code.\n",
    "\n",
    "The preprocessing pipeline handles both data cleaning and storage optimization through the `MoviePreprocessor` class; then, the data is stored in a SQLite table.\n"
   ],
   "id": "9019b5f264c7e6bc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-04T06:27:57.941631Z",
     "start_time": "2024-12-04T06:27:57.922529Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = pd.DataFrame(preprocessed_movies)\n",
    "\n",
    "for col in ['genres', 'directors', 'writers', 'cast']:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].apply(lambda x: '|'.join(x) if x else '')\n",
    "\n",
    "df.head()"
   ],
   "id": "d54cc42f4740da3b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                         title  \\\n",
       "0                               101 dalmatians   \n",
       "1                        101 dalmatians (1996)   \n",
       "2  101 dalmatians ii: patch's london adventure   \n",
       "3                               102 dalmatians   \n",
       "4                 20,000 leagues under the sea   \n",
       "\n",
       "                                         description rating   runtime  \\\n",
       "0  walt disneyâ€™s beloved animated masterpiece 101...      g  1h 19min   \n",
       "1  cruella de vil dognaps all of the dalmatian pu...      g             \n",
       "2  the adventure begins when patch, gets the chan...      g             \n",
       "3  oddball, the spotless dalmatian puppy on a sea...      g             \n",
       "4  climb aboard the nautilus and into a strange u...      g             \n",
       "\n",
       "                                          genres  \\\n",
       "0              family|animation|action-adventure   \n",
       "1            family|comedy|live action|adventure   \n",
       "2              family|animation|action-adventure   \n",
       "3            family|comedy|live action|adventure   \n",
       "4  live action|adventure|science fiction|fantasy   \n",
       "\n",
       "                                           directors  \\\n",
       "0  hamilton luske|wolfgang reitherman|clyde geronimi   \n",
       "1                                      stephen herek   \n",
       "2                           brian smith|jim kammerud   \n",
       "3                                         kevin lima   \n",
       "4                                  richard fleischer   \n",
       "\n",
       "                                             writers cast  year  \\\n",
       "0                              bill peet|dodie smith       1961   \n",
       "1                            dodie smith|john hughes       1996   \n",
       "2             garrett k. schiff|dodie smith|dan root       2003   \n",
       "3  noni white|bob tzudiker|dodie smith|brian rega...       2000   \n",
       "4                            jules verne|earl felton       1954   \n",
       "\n",
       "                                       slug   type  \n",
       "0                       101-dalmatians-1961  movie  \n",
       "1                       101-dalmatians-1996  movie  \n",
       "2  101-dalmatians-2-patchs-london-adventure  movie  \n",
       "3                            102-dalmatians  movie  \n",
       "4               20000-leagues-under-the-sea  movie  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>rating</th>\n",
       "      <th>runtime</th>\n",
       "      <th>genres</th>\n",
       "      <th>directors</th>\n",
       "      <th>writers</th>\n",
       "      <th>cast</th>\n",
       "      <th>year</th>\n",
       "      <th>slug</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101 dalmatians</td>\n",
       "      <td>walt disneyâ€™s beloved animated masterpiece 101...</td>\n",
       "      <td>g</td>\n",
       "      <td>1h 19min</td>\n",
       "      <td>family|animation|action-adventure</td>\n",
       "      <td>hamilton luske|wolfgang reitherman|clyde geronimi</td>\n",
       "      <td>bill peet|dodie smith</td>\n",
       "      <td></td>\n",
       "      <td>1961</td>\n",
       "      <td>101-dalmatians-1961</td>\n",
       "      <td>movie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101 dalmatians (1996)</td>\n",
       "      <td>cruella de vil dognaps all of the dalmatian pu...</td>\n",
       "      <td>g</td>\n",
       "      <td></td>\n",
       "      <td>family|comedy|live action|adventure</td>\n",
       "      <td>stephen herek</td>\n",
       "      <td>dodie smith|john hughes</td>\n",
       "      <td></td>\n",
       "      <td>1996</td>\n",
       "      <td>101-dalmatians-1996</td>\n",
       "      <td>movie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101 dalmatians ii: patch's london adventure</td>\n",
       "      <td>the adventure begins when patch, gets the chan...</td>\n",
       "      <td>g</td>\n",
       "      <td></td>\n",
       "      <td>family|animation|action-adventure</td>\n",
       "      <td>brian smith|jim kammerud</td>\n",
       "      <td>garrett k. schiff|dodie smith|dan root</td>\n",
       "      <td></td>\n",
       "      <td>2003</td>\n",
       "      <td>101-dalmatians-2-patchs-london-adventure</td>\n",
       "      <td>movie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>102 dalmatians</td>\n",
       "      <td>oddball, the spotless dalmatian puppy on a sea...</td>\n",
       "      <td>g</td>\n",
       "      <td></td>\n",
       "      <td>family|comedy|live action|adventure</td>\n",
       "      <td>kevin lima</td>\n",
       "      <td>noni white|bob tzudiker|dodie smith|brian rega...</td>\n",
       "      <td></td>\n",
       "      <td>2000</td>\n",
       "      <td>102-dalmatians</td>\n",
       "      <td>movie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20,000 leagues under the sea</td>\n",
       "      <td>climb aboard the nautilus and into a strange u...</td>\n",
       "      <td>g</td>\n",
       "      <td></td>\n",
       "      <td>live action|adventure|science fiction|fantasy</td>\n",
       "      <td>richard fleischer</td>\n",
       "      <td>jules verne|earl felton</td>\n",
       "      <td></td>\n",
       "      <td>1954</td>\n",
       "      <td>20000-leagues-under-the-sea</td>\n",
       "      <td>movie</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3. Vectorization",
   "id": "d93c32662e499d13"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-04T06:40:25.722773Z",
     "start_time": "2024-12-04T06:40:24.224863Z"
    }
   },
   "cell_type": "code",
   "source": "embedder = MovieEmbedder(pm)",
   "id": "1f6afbf0168357da",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "### a. Generating embeddings with Google AI's T5  & b. Vector storage with FAISS index\n",
    "\n",
    "\n",
    "The vectorization pipeline leverages Google's T5-base model to generate semantic embeddings for movie data, combining movie titles, descriptions, genres, cast, and other metadata into rich vector representations. \n",
    "\n",
    "The implementation uses batch processing and GPU acceleration (via Apple Metal when available) for efficient processing of the ~700 movie dataset. \n",
    "\n",
    "Generated embeddings are stored using FAISS (Facebook AI Similarity Search), implementing an IVF (Inverted File) index that enables sub-linear search complexity and efficient similarity queries.\n",
    "\n",
    "\n",
    "The pipeline processes each movie's textual data and converts it into a 768-dimensional embedding vector. \n",
    "\n",
    "These embeddings are organized in a FAISS index optimized for CPU-based similarity search, allowing for quick retrieval + maintaining a reasonable memory footprint. \n",
    "\n",
    "The system automatically handles device selection (GPU/CPU), includes progress tracking, and implements efficient batch processing to manage memory usage, making it scalable for larger datasets."
   ],
   "id": "3e5382d5ea5c70ed"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-12-04T06:40:29.040006Z"
    }
   },
   "cell_type": "code",
   "source": "embedder.process_embeddings(movies=preprocessed_movies, use_parallel=True)",
   "id": "7d535a98a3dbe54f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting embedding generation and indexing\n",
      "Creating text representations for 699 movies...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Generating movie texts:   0%|          | 0/699 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3419417e7ff14838bb9d24e0e376552c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up slug mappings...\n",
      "Generating embeddings in batches of 32...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/22 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "029a832ea63341eb9638544a5e29640c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting batch 1/22\n",
      "Batch size: 32\n",
      "Processing 32 texts for embedding\n",
      "Running model inference...\n",
      "Converting to numpy...\n",
      "Completed batch 1/22\n",
      "Starting batch 2/22\n",
      "Batch size: 32\n",
      "Processing 32 texts for embedding\n",
      "Running model inference...\n",
      "Converting to numpy...\n",
      "Completed batch 2/22\n",
      "Starting batch 3/22\n",
      "Batch size: 32\n",
      "Processing 32 texts for embedding\n",
      "Running model inference...\n",
      "Converting to numpy...\n",
      "Completed batch 3/22\n",
      "Starting batch 4/22\n",
      "Batch size: 32\n",
      "Processing 32 texts for embedding\n",
      "Running model inference...\n",
      "Converting to numpy...\n",
      "Completed batch 4/22\n",
      "Starting batch 5/22\n",
      "Batch size: 32\n",
      "Processing 32 texts for embedding\n",
      "Running model inference...\n",
      "Converting to numpy...\n",
      "Completed batch 5/22\n",
      "Starting batch 6/22\n",
      "Batch size: 32\n",
      "Processing 32 texts for embedding\n",
      "Running model inference...\n",
      "Converting to numpy...\n",
      "Completed batch 6/22\n",
      "Starting batch 7/22\n",
      "Batch size: 32\n",
      "Processing 32 texts for embedding\n",
      "Running model inference...\n",
      "Converting to numpy...\n",
      "Completed batch 7/22\n",
      "Starting batch 8/22\n",
      "Batch size: 32\n",
      "Processing 32 texts for embedding\n",
      "Running model inference...\n",
      "Converting to numpy...\n",
      "Completed batch 8/22\n",
      "Starting batch 9/22\n",
      "Batch size: 32\n",
      "Processing 32 texts for embedding\n",
      "Running model inference...\n",
      "Converting to numpy...\n",
      "Completed batch 9/22\n",
      "Starting batch 10/22\n",
      "Batch size: 32\n",
      "Processing 32 texts for embedding\n",
      "Running model inference...\n",
      "Converting to numpy...\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 4. Query and Retrieve",
   "id": "c536858dc4150b4f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "qr = SearchAndRetrieval()",
   "id": "cc914eff6f732767"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "### a. Text query for similarity search"
   ],
   "id": "95505db0ba31043b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# Character types\n",
   "id": "bdf21416c9f111f1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "dc8d2bcb2230af82"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "4251ca6887e8a830"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "235bcc597cc5d406"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "c5dbc1146f2d4886"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "1bdeca1ca80b9f3d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### b. Retrieval-Augmented Generation",
   "id": "c216a0ec41c2d788"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "fa77ddec80e5e7d1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 5. Documentation ",
   "id": "3f32bb5f09d94145"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "409c253033ee19de"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 6. Bonus\n",
    "\n",
    "I'm also integrating the \"bonus\" functionalities in the worker classes, since logging and parallel processing will be useful.\n",
    "\n",
    "For more detail, please refer to `project_utils.py` in the source code for these bonus processes.\n",
    "\n",
    "These, among some other project utility functions, are found in the `ProjectManager` class."
   ],
   "id": "da1a1bacd0992914"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### a. Pipeline logging",
   "id": "89fd430a9c895b14"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": 3,
   "source": "#load logging",
   "id": "e82440aedf204fab"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### b. Parallel processing\n",
    "\n",
    "A rudimentary implementation in `project_utils.py` for threading/pooling of operations.\n",
    "\n",
    "This is an example of a useful method for processing a large amount of data (eg. a richer corpus of text data)"
   ],
   "id": "a7fc3fb79e94aff"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "3bfa02201ff39641"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "f15a3d6b4b6a92ba"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
